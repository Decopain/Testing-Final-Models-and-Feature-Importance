# Testing-Final-Models-and-Feature-Importance

<h2>Description</h2>
The primary objective of this notebook focuses on testing and evaluating various machine learning models, including Random Forest, XGBoost, and CatBoost. The initial steps involve importing essential libraries, reading in the dataset 'final_data.csv', and preparing the data by removing certain columns and segmenting it into training, validation, and testing sets. Each of the aforementioned models is then likely trained and assessed individually. The notebook also emphasizes understanding the importance of different features used in predictions. Towards the end, an ensemble approach is introduced, which aims to combine the strengths of the individual models to enhance predictive accuracy.
<br />


<h2>Languages and Utilities Used</h2>

- <b>Python</b> 

<h2>Environments Used </h2>

- <b>Windows 10</b> (21H2)
- <b>Jupyter Notebooks</b> 

<h2>Program walk-through:</h2>

<p align="center">
FEATURE IMPORTANCE: <br/>
 
<img width="851" alt="Screenshot 2023-10-05 124604" src="https://github.com/Decopain/Random-Forrest-Classifier-and-XGBoost-Hybrid-Ensamble-for-Binary-Classification/assets/17460080/45d72617-7169-4aa8-bef8-70d497928d29">
<br />
<br />
<p align="center">
ENSEMBLE MODEL RESULTS:  <br/>

<img width="935" alt="mhjytv" src="https://github.com/Decopain/Random-Forrest-Classifier-and-XGBoost-Hybrid-Ensamble-for-Binary-Classification/assets/17460080/243a0e68-8dc2-404b-8b30-aef47854a7ae">
<br />
<br />
